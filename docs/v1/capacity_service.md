# Capacity Service

Servers used for the provisioning of computer resources for your Kubernetes cluster may come in different flavors: cloud-based virtual machines,  on-premise bare-metal servers or on-premise virtual machines. In addition, each cloud service provider (e.g Amazon AWS) offers its vendor server types with different hardware and memory parameters. Managing the selection, instantiation, and scaling of all these diverse server types manually may be a complicated task. 

Supergiant **Capacity Service** is a solution to this problem. The Capacity Service is Supergiant's way of abstracting servers from application management and deployment, which allows the user to focus only on how much CPU, RAM, and disc applications need, and not which flavor of a server to use for each application. If you imagine _containerization_ to be similar to hardware-level virtualization (hypervisors partitioning big host machines in the cloud into multiple virtual machines), then the following analogy could be made. Without the Supergiant Capacity Service, running a container orchestration platform like Kubernetes forces DevOps engineers to manage 2 levels of capacity -  that is, they must not only worry about container resource allocation but also _server allocation_. It would be equally difficult to imagine AWS requiring its users not only to request new servers but also request additional capacity in the region ahead of time! 

Of course, that would be silly -- cloud servers are generally _on-demand_. That's what the Capacity Service does for Kubernetes containers. Containers can be provisioned on-demand without worrying about server capacity. Supergiant will handle creating Nodes when over capacity, and (gently) deleting Nodes when sufficiently under capacity.

